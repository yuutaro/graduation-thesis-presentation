\section{関連研究}
\label{chap:related_work}

本章では，ソフトウェアテストデータの生成手法，大規模言語モデル（LLM）のデータ生成への応用に関する先行研究を概観し，本研究の位置づけを明確にする．

\subsection{ソフトウェアテストデータの生成手法}
% 2.1 ルールベースおよびランダムサンプリングによるデータ生成
Webアプリケーションの開発現場において，動作検証や負荷試験のためのテストデータ生成は不可欠な工程であり，主に構文的整合性やコード網羅率の確保に主眼が置かれてきた\cite{edvardsson1999survey}．

代表的なアプローチとして，Faker.js \cite{fakerjs} や JavaFaker \cite{javafaker} に代表されるライブラリを用いたランダム生成手法が存在する．これらは，正規表現や定義済みの辞書に基づき，氏名，住所，メールアドレスといった形式が決まったデータを大量に生成することに長けている．
また，Mockaroo \cite{mockaroo} のようなデータ生成サービスでは，GUI上でスキーマ定義を行うことで，ある程度の外部キー制約を満たしたCSVやSQLデータを生成可能である．
さらに，近年のWeb開発フレームワーク（例：Prisma \cite{prisma} などのORM）には，開発初期のシードデータ（初期データ）を投入する機能が標準で備わっていることが多いが，これらも基本的には開発者が手動で作成した固定データか，あるいは前述のFaker等で生成したランダムデータを投入するための機構に留まる．

しかし，これらの手法は，本来アプリケーションのログイン機能や権限管理といった基本機能の動作検証を目的としたものであり，データ間の複雑な意味的整合性や文脈を再現することを主眼としていない．
例えば，「居住地が日本であるにも関わらず住所がニューヨークに設定されている」といった整合性の欠如や，「ユーザー間のメッセージ交換に見られる時系列的な因果関係」を含む複雑なシナリオを再現することは，単純なランダムサンプリングでは原理的に困難である．
本研究が対象とするCtoCプラットフォームのような，ユーザー間の相互作用や作品の背景ストーリーが重要となるシステムの検証において，これらの既存手法は不十分であると言える．

\subsection{統計的・機械学習的なデータ合成}
% 2.2 統計的・機械学習的なデータ合成
統計モデルや機械学習を用いて，既存データセットの分布を学習し，類似した特性を持つデータを新たに生成する手法も広く研究されている．
代表的な手法として，条件付きGANを用いたCTGAN \cite{xu2019modeling} や，リレーショナルデータベース全体の生成に特化したベンチマークであるSyntheRela \cite{jurkovic2025syntherela} において評価されているSDV（Synthetic Data Vault）などが挙げられる．

これらの手法は，プライバシー保護（匿名化）やデータ拡張（アップサンプリング）において強力なツールとなるが，適用するには「学習元となる大量の既存データ」が存在することが前提となる．
したがって，新規サービスの立ち上げ時のような「学習データが全く存在しない状態」においては適用することができない．
本研究は，学習データが存在しないフェーズにおいて，LLMの知識と創造性を利用してゼロからデータを生成するアプローチをとるため，これらの統計的手法とは適用領域が根本的に異なる．

\subsection{LLMを用いたリレーショナルデータの構築・操作}
% 2.3 LLMを用いたリレーショナルデータの構築・操作
近年，LLMの高度な言語理解能力を活かし，複雑なスキーマ構造を持つリレーショナルデータを扱う研究が進展している．

Liら \cite{li2025omnisql} のOmniSQLは，Text-to-SQLモデルの学習用データ不足を解消するために，Web上の表データから多様なデータベーススキーマとSQLクエリを自動合成するフレームワークを提案した．また，Sadiaら \cite{sadia2025squid} のSQUiDは，非構造化テキストからリレーショナルデータベースを構築するタスク（Text2R）において，LLMに直接SQLを書かせるのではなく，スキーマ設計とデータ投入のプロセスを分離することで整合性を高める手法を示した．
さらに，Kimら \cite{kim2026refuge} のReFuGeは，予測タスクの精度向上のために，LLMエージェントを用いてリレーショナルデータベースから有効な特徴量を自動生成する枠組みを提案している．

これらの研究は，LLMが複雑なリレーション構造を理解・操作できることを示しているが，その主目的はあくまで「学習データの作成」や「既存情報の抽出・分析」にある．
本研究は，これらの研究と技術基盤（LLMエージェント，プロセス分解アプローチ）を共有しつつ，目的を「架空の社会的シナリオに基づく新規データの創造」に置く点で独自性がある．

\subsection{社会シミュレーションと生成的エージェント}
% 2.4 社会シミュレーションと生成的エージェント
LLMを用いて人間らしい振る舞いをシミュレートする研究として，Parkら \cite{park2023generative} のGenerative Agentsが挙げられる．
彼らは，記憶と計画を持つ複数のエージェントを仮想空間内で生活させ，エージェント同士の創発的な社会的相互作用（例：パーティーの企画）が生まれることを実証した．

この「記憶に基づく一貫した行動生成」という概念は本研究の基礎となっているが，Generative Agentsの出力は自然言語のログ（非構造化データ）であり，そのままではリレーショナルデータベースの厳密な制約（外部キーやデータ型）を満たすテストデータとして利用できない．
本研究の貢献は，Generative Agentsのような「人間らしい文脈や動機」を維持しつつ，それをSQUiDのような「構造的整合性」を持つリレーショナルデータとして出力するためのシステムアーキテクチャを提案する点にある．
