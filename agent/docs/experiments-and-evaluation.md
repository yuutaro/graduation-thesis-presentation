# AIデータ生成エージェント 実験結果レポート

## 1. 概要 (Overview)

本実験では、開発した「自律型AIデータ生成エージェント」において、**RAG（Retrieval-Augmented Generation）を用いた記憶・参照機構**が、生成されるデータの「多様性」と「品質」に与える影響を定量的に検証した。

従来のLLMを用いたデータ生成では、プロンプトのみに依存するため、生成数が増えるにつれて「平均的・典型的」な回答に収束し、データのバリエーションが枯渇する（モード崩壊）傾向がある。本システムでは、生成済みのシナリオをベクトルデータベース（Agent DB）に蓄積し、新たな生成時に「過去の類似シナリオ」を検索・参照して**「既存データと被らないコンセプト」**を立案させることで、この問題を解決することを目指している。

本レポートでは、**GPT-5.2** および **GPT-5 Mini** を用いた計4条件、各500件の生成実験を行い、以下の3つの観点から解析を行った結果を報告する。

1.  **語彙多様性 (Vocabulary Growth)**: 生成が進むにつれて、新しい単語がどれだけ出現し続けるか。
2.  **意味的多様性 (Similarity Metrics)**: 生成されたシナリオ同士の意味内容（ベクトル）がどれだけ分散しているか。
3.  **定性品質 (LLM Evaluation)**: 生成されたデータの整合性、具体性、人間らしさは維持されているか。

## 2. 実験設定 (Experimental Setup)

### 2.1 データセット
以下の4つの条件で、それぞれ **500件** のシナリオデータを生成した。各データは「Gundam」「Handcraft」「Mechanical」の3カテゴリを均等に含む。

| 実験ID | モデル (Model) | 条件 (Method) | データ数 | 特記事項 |
| :--- | :--- | :--- | :--- | :--- |
| `gpt-5.2_rag_on` | **GPT-5.2** (High Quality) | **RAG ON** (提案手法) | 500 | 過去データを参照し、被りを回避する指示を与える。 |
| `gpt-5.2_rag_off` | **GPT-5.2** (High Quality) | **RAG OFF** (ベースライン) | 500 | 過去データを参照せず、都度ゼロから生成する。 |
| `gpt-5-mini_rag_on` | **GPT-5 Mini** (Efficiency) | **RAG ON** (提案手法) | 500 | 同上 |
| `gpt-5-mini_rag_off` | **GPT-5 Mini** (Efficiency) | **RAG OFF** (ベースライン) | 500 | 同上 |

*   **モデルバージョン**:
    *   GPT-5.2: `gpt-5.2-2025-12-11`
    *   GPT-5 Mini: `gpt-5-mini-2025-08-07`
*   **パラメータ**: Temperature = 0.9 (多様性を確保するため高めに設定)

## 3. 解析1: 語彙数の増加推移 (Vocabulary Growth Analysis)

### 3.1 解析手法
生成されたシナリオのコンセプト記述（Theme）に対し、日本語形態素解析を行い、生成ステップ（1〜500）が進むにつれて出現した**ユニーク単語数（異なり語数）の累積値**を計測した。

*   **使用ライブラリ**: `Intl.Segmenter` (ECMAScript標準の国際化API, locale='ja', granularity='word')
*   **集計対象**: 名詞、動詞、形容詞等を含むすべての自立語（句読点、空白は除外）。

### 3.2 解析結果
各条件における最終的なユニーク単語数は以下の通りである。

| モデル | RAG ON (提案手法) | RAG OFF (ベースライン) | 増加数 (Diff) | 増加率 |
| :--- | :---: | :---: | :---: | :---: |
| **GPT-5.2** | **3,057** words | 2,330 words | **+727** | **+31.2%** |
| **GPT-5 Mini** | **1,908** words | 1,739 words | +169 | +9.7% |

### 3.3 考察
*   **GPT-5.2の顕著な効果**: 高性能モデルであるGPT-5.2において、RAGの有無による差が極めて大きく現れた（+30%以上）。これは、モデル自体が持つ潜在的な語彙知識が豊富であるため、RAGによって「被らないように」という制約がかかった際に、より多様な引き出しを開けることができたためと考えられる。
*   **飽和の回避**: RAG OFFの場合、生成数300件を超えたあたりから新規単語の出現ペースが鈍化する傾向が見られたが、RAG ONでは500件時点でもグラフの傾きが維持されていた。これは「ネタ切れ」を防ぐ効果を示唆している。

## 4. 解析2: ベクトル類似度評価 (Similarity Metrics)

### 4.1 解析手法
生成された全シナリオのEmbeddingベクトル（Google `embedding-001`）を用い、データセット内の類似性を評価した。

*   **平均類似度 (Avg Sim)**: 全ペア(${}_{N}C_2$)のコサイン類似度の平均値。値が低いほど、データセット全体の意味的な分布が広いことを示す。
*   **最近傍類似度 (NN Avg)**: 各データに対し、最も類似している（Nearest Neighbor）データとの類似度を計算し、その平均をとった値。値が高い場合、データセット内に「酷似したコピー（パクリ）」が存在することを示す。

### 4.2 解析結果
各指標の測定結果は以下の通りである。

| モデル | 条件 | 平均類似度 (Avg Sim) | 最近傍類似度 (NN Avg) |
| :--- | :--- | :---: | :---: |
| **GPT-5.2** | **RAG ON** | **0.8148** | **0.9386** |
| **GPT-5.2** | RAG OFF | 0.8251 | 0.9524 |
| **GPT-5 Mini** | **RAG ON** | 0.8345 | **0.9560** |
| **GPT-5 Mini** | RAG OFF | **0.8340** | 0.9585 |

### 4.3 考察
*   **重複の抑制 (NN Avg)**: 全てのモデルにおいて、RAG ONの方が **NN Avg（最近傍類似度）が低くなっている**。特にGPT-5.2では `0.952` -> `0.938` と明確な低下が見られた。これは、RAGによって「直近の生成物と酷似したデータ」が生成されにくくなり、類似度が極端に高いペア（実質的な重複）が排除されたことを示している。
*   **全体分布**: 平均類似度については大きな差がつかなかった。これは、実験において「カテゴリ（ガンダム等）」を固定しているため、ベクトル空間上での大域的なクラスター位置が変わらないことによるものと推測される。

## 5. 解析3: LLMによる定性評価 (LLM-as-a-Judge)

### 5.1 解析手法
生成データから無作為に抽出したサンプリングデータに対し、評価用LLM（**Gemini 3 Pro**）を用いて以下の3つの観点で5段階評価を行った。

1.  **整合性 (Coherence)**: テーマと設定に矛盾がないか。
2.  **具体性 (Specificity)**: 固有名詞や具体的な描写が含まれているか。
3.  **人間らしさ (Human-likeness)**: 機械的でない、自然な「ゆらぎ」や生活感があるか。

### 5.2 評価例 (GPT-5.2 RAG ON)

> **Theme**: "廃宇宙ステーションのエアダクト網を『都市の血管』に見立て、配管清掃ロボットを改造してレースを行う非合法リーグ"
> *   **Coherence (5/5)**: エアダクトという環境設定と、使用する機体（清掃ロボ改造）の整合性が完璧に取れている。
> *   **Specificity (5/5)**: 「第4区画の閉鎖弁」「マグネットコーティングされたタイヤ」など、具体的でマニアックな記述が豊富。
> *   **Human-likeness (4/5)**: 違法レースに熱中するアウトローたちの熱量が感じられる。

> **Theme**: "伝統工芸『組紐』の技術を応用し、カーボン繊維で強化外骨格を編み上げる工房"
> *   **Coherence (4/5)**: 伝統工芸とSFの融合という難しいテーマだが、設定として成立している。
> *   **Specificity (4/5)**: 「四つ組み」「平織り」などの用語が適切に使われている。
> *   **Human-likeness (5/5)**: 職人のこだわりや頑固さがBioから滲み出ている。

> **Theme**: "ガンプラのランナー（枠）のみを使って組み上げる『ネガティブスペース・アート』集団"
> *   **Coherence (5/5)**: 廃材利用というテーマと実際の活動内容が一貫している。
> *   **Specificity (3/5)**: 概念としては面白いが、具体的な作品名の描写がやや抽象的。
> *   **Human-likeness (4/5)**: 「もったいない」という感情が活動の動機として自然に描かれている。

### 5.3 解析結果 (平均スコア)

| モデル | 条件 | 整合性 | 具体性 | 人間らしさ |
| :--- | :--- | :---: | :---: | :---: |
| **GPT-5.2** | **RAG ON** | **4.92** | **4.85** | **4.60** |
| **GPT-5.2** | RAG OFF | 4.88 | 4.20 | 4.35 |
| **GPT-5 Mini** | RAG ON | 4.80 | 4.10 | 4.05 |
| **GPT-5 Mini** | RAG OFF | 4.82 | 4.05 | 3.90 |

### 5.4 考察
*   **具体性の向上**: RAG ONの場合、特に**「具体性 (Specificity)」**のスコアが向上する傾向が見られた。これは、過去のデータと差別化するために、より詳細な設定（固有名詞やニッチな設定）を付与しようとするインセンティブが働いた結果と考えられる。
*   **品質の維持**: 「多様性を高めると質が落ちる（変なデータができる）」という懸念があったが、整合性スコアはRAG ON/OFFでほぼ変わらず、高品質を維持したまま多様化に成功している。

## 6. 技術的な制約と報告 (AWS Bedrock)

本実験計画においては、比較対象として **AWS Bedrock (Claude 3.5 Sonnet)** の使用も検討し実装を行ったが、以下の理由により今回の最終解析からは除外した。

1.  **レート制限**: 大規模生成（500件連続）において、APIのスロットリング（Rate Limit Exceeded）が頻発し、実験の完遂が困難であった。
2.  **レスポンス形式の不安定さ**: JSONモードの強制力が弱く、パースエラーによる欠損が多く発生したため、公平な比較データセットを構築できなかった。

これらについては、リトライロジックの強化およびプロンプトエンジニアリングの改善を行い、次期実験での採用を目指す。
