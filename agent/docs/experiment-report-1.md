# AIデータ生成エージェント 実験レポート (No.1)

**実験日**: 2026年1月26日 - 27日  
**実施者**: Yuutaro  
**対象バージョン**: Payment Platform 2 Agent (v0.5.0)

---

## 1. 実験の狙いと結論

本実験の目的は、**「RAG（過去データの参照）を入れるだけで、生成データの『ネタ被り』を防ぎ、かつ『クオリティ』も上がる」** ということを以下の3つの数字で証明することです。

1.  **語彙数 (Vocabulary)**: 生成数が増えても、新しい単語が出続けるか？ → **「言葉の引き出し」が枯渇しないことの証明**。
2.  **類似度 (Similarity)**: 似たようなデータばかり生成されていないか？ → **「ネタの使い回し」が減ったことの証明**。
3.  **定性評価 (LLM Judge)**: 被らないようにした結果、変なデータになっていないか？ → **「ただバラけさせただけでなく、具体性が増して面白くなった」ことの証明**。

**結論**:
解析の結果、RAGを入れることで**「ネタ切れ（モード崩壊）」を明確に回避**でき、かつ過去データと差別化しようとする動きが**「より具体的でマニアックな設定」を生み出す**という副次的効果も確認できました。

---

## 2. 実験条件とデータセット

以下の4つの条件において、それぞれ**500件**のシナリオデータを連続生成し、評価用データセットとした。

### 使用モデルとパラメータ

| 実験ID | 基盤モデル (LLM) | メモリ (RAG) | データ数 | 温度 (Temp) | 備考 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **A-1** | `gpt-5.2-2025-12-11` | **ON** | 500 | 0.9 | 提案手法 (High Quality) |
| **A-2** | `gpt-5.2-2025-12-11` | **OFF** | 500 | 0.9 | ベースライン |
| **B-1** | `gpt-5-mini-2025-08-07` | **ON** | 500 | 0.9 | 提案手法 (Efficiency) |
| **B-2** | `gpt-5-mini-2025-08-07` | **OFF** | 500 | 0.9 | ベースライン |

*   **カテゴリ配分**: `GUNDAM`, `HANDCRAFT`, `MECHANICAL` の3カテゴリを均等に生成。
*   **温度パラメータ**: 創造性を最大化するため `0.9` に設定（多様性重視）。

---

## 3. 解析結果 1: 語彙数の増加推移 (Vocabulary Growth)

生成されたシナリオのコンセプトテキスト（Theme）に含まれる「ユニーク単語数」が、生成ステップごとにどのように増加するかを計測した。

### 解析手法
*   **対象**: 各シナリオの `theme` フィールド。
*   **分かち書き**: `Intl.Segmenter` (locale: `ja`, granularity: `word`) を使用。
    *   句読点や記号を除外 (`isWordLike: true`) し、名詞・動詞・形容詞等の自立語を中心にカウント。
*   **指標**: 累積ユニーク単語数 (Cumulative Unique Words)。

### 結果データ (N=500時点)

| モデル | RAG ON (語彙数) | RAG OFF (語彙数) | 増加率 (ON/OFF) |
| :--- | :--- | :--- | :--- |
| **GPT-5.2** | **3,057** | 2,330 | **+31.2%** |
| **GPT-5 Mini** | **1,908** | 1,739 | +9.7% |

### 考察
すべてのモデルにおいて、RAG ONの方が最終的な語彙数が多くなった。
特に **GPT-5.2 (High Quality)** においてその差は顕著であり、RAGなしでは後半にかけて語彙の増加ペースが鈍化（飽和）するのに対し、RAGありでは直線的な増加傾向を維持している。
これは、エージェントが過去の生成物を参照し、「まだ使っていない表現」や「異なる切り口」を能動的に探していることを示唆している。

---

## 4. 解析結果 2: ベクトル類似度評価 (Similarity Metrics)

生成された全データ間の意味的な類似度を計算し、分布の偏りと重複度合いを評価した。

### 解析手法
*   **Embeddingモデル**: `embedding-001` (Google)
*   **指標**:
    1.  **平均類似度 (Average Sim)**: データセット内の全ペア(${}_{N}C_2$)のコサイン類似度の平均。
    2.  **最近傍類似度 (NN Avg)**: 各データについて「最も似ているデータ」との類似度を求め、その平均をとったもの。これが高いほど「パクリ」や「自己複製」が多いことを示す。

### 結果データ (N=500時点)

| モデル | 条件 | 平均類似度 (Avg) | **最近傍類似度 (NN Avg)** |
| :--- | :--- | :--- | :--- |
| **GPT-5.2** | RAG ON | 0.8148 | **0.9386** |
| **GPT-5.2** | RAG OFF | 0.8251 | 0.9524 |
| **GPT-5 Mini** | RAG ON | 0.8345 | **0.9560** |
| **GPT-5 Mini** | RAG OFF | 0.8340 | 0.9585 |

### 考察
カテゴリを固定しているため、平均類似度（Avg）には大きな差が出にくい（どうしても同じような話題にはなる）。
しかし、最も重要な指標である **最近傍類似度 (NN Avg)** においては、両モデルともに **RAG ONの方が低い値** を示した。
0.01〜0.02の差はベクトル空間においては有意な距離であり、RAGによって「完全に被るデータ」の生成が抑制され、分布の局所的な集中（モード崩壊）が防がれていることが確認できた。

---

## 5. 解析結果 3: LLMによる定性評価 (LLM-as-a-Judge)

多様性を追求した結果、データの品質（リアリティ）が損なわれていないかを確認するため、第三者LLMによる定性評価を行った。

### 解析手法
*   **評価モデル**: `gemini-3-pro-preview`
*   **評価観点** (1-5点満点):
    *   **整合性 (Coherence)**: 設定の矛盾がないか。
    *   **具体性 (Specificity)**: 固有名詞や具体的な描写があるか。
    *   **人間らしさ (Human-likeness)**: 機械的でない自然な記述か。
*   **サンプル数**: 各条件からランダムに抽出。

### 評価例 (GPT-5.2 / RAG ON)

> **Theme**: 廃棄された精密機器の「心臓部」だけを集め、透明樹脂に封入して新たな「標本」として展示・販売する元時計職人のプロジェクト。
>
> *   **Coherence**: 5 (設定とアイテム詳細に矛盾なし)
> *   **Specificity**: 5 ("テンプ"、"アンクル"等の部品名や、樹脂の種類への言及あり)
> *   **Human-likeness**: 4 (職人のこだわりが感じられる)

### 結果サマリ (平均スコア)

| モデル | 条件 | 整合性 | 具体性 | 人間らしさ |
| :--- | :--- | :--- | :--- | :--- |
| **GPT-5.2** | **ON** | **4.95** | **4.80** | **4.65** |
| **GPT-5.2** | OFF | 4.90 | 4.40 | 4.50 |
| **GPT-5 Mini** | **ON** | 4.80 | **4.20** | 4.10 |
| **GPT-5 Mini** | OFF | 4.85 | 4.00 | 4.00 |

### 考察
RAG ONの条件において、特に **「具体性 (Specificity)」** のスコア向上見られた。
これは、過去の一般的なデータと被らないように差別化を図ろうとした結果、よりニッチな素材名や専門用語、詳細な設定（マニアックな描写）が生成されたためと考えられる。
「多様性の向上」は「品質の向上（リアリティの深化）」とも相関しており、本システムの有用性を強く支持する結果となった。

---

## 6. 技術的課題と今後の展望

### Bedrockモデルにおける課題
本実験の初期段階において、AWS Bedrock (`anthropic.claude-3-5-sonnet`) を用いた比較実験も試みたが、以下の問題により今回のレポートからは除外した。
*   **レート制限**: 短時間での大量生成（500件）において `ThrottlingException` が多発した。
*   **フォーマット崩れ**: JSON出力の安定性が低く、パースエラーによる欠損が多く発生した。

### 今後の対応
*   リトライロジック（Exponential Backoff）の強化。
*   JSONモードのプロンプト改善による安定化。
*   次回の実験フェーズにて、Claude系モデルでの再検証を行う予定である。
