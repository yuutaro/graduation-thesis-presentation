
import * as fs from 'fs';
import * as path from 'path';
import { fileURLToPath } from 'url';
import { z } from "zod";
import { createChatModel, AVAILABLE_MODELS } from '../../../../src/utils/model-factory.js';
import dotenv from 'dotenv';
import pLimit from 'p-limit'; // For concurrency control

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Explicitly load .env from agent root (../../../../.env)
dotenv.config({ path: path.resolve(__dirname, '../../../../.env') });

// --- Configuration ---
const DEFAULT_SAMPLE_SIZE = 20; // Default samples per file
const CONCURRENCY_LIMIT = 5; // Max concurrent LLM calls
const EVAL_MODEL = AVAILABLE_MODELS.GEMINI_3_PRO; // Judge Model

// --- Schemas ---

const EvaluationSchema = z.object({
  coherence: z.number().min(1).max(5).describe("æ•´åˆæ€§: è¨­å®šã¨ç”Ÿæˆç‰©ã«çŸ›ç›¾ãŒãªã„ã‹ (1:çŸ›ç›¾ã ã‚‰ã‘ - 5:å®Œå…¨ã«æ•´åˆ)"),
  specificity: z.number().min(1).max(5).describe("å…·ä½“æ€§: å›ºæœ‰åè©ã‚„å…·ä½“çš„ãªæŠ€æ³•ãƒ»ç´ æãƒ»èƒŒæ™¯æå†™ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ (1:æŠ½è±¡çš„ãƒ»ä¸€èˆ¬çš„ - 5:éå¸¸ã«å…·ä½“çš„ãƒ»ãƒãƒ‹ã‚¢ãƒƒã‚¯)"),
  humanLikeness: z.number().min(1).max(5).describe("äººé–“ã‚‰ã—ã•: æ„Ÿæƒ…ã€ç†±é‡ã€ç”Ÿæ´»æ„Ÿã€ã‚ã‚‹ã„ã¯ã€Œæ‰‹ç™–ã€ã§ã¯ãªã„è‡ªç„¶ãªä¸è¦å‰‡æ€§ãŒã‚ã‚‹ã‹ (1:æ©Ÿæ¢°çš„ - 5:äººé–“å‘³ãŒã‚ã‚‹)"),
  reason: z.string().describe("è©•ä¾¡ã®ç†ç”±ï¼ˆçŸ­ãï¼‰"),
});

type EvaluationResult = z.infer<typeof EvaluationSchema> & {
  theme: string;
};

type FileEvaluationSummary = {
  filename: string;
  modelName: string; // Extracted from filename or config
  rag: boolean;      // Extracted from filename or config
  sampleSize: number;
  coherence: number;
  specificity: number;
  humanLikeness: number;
  details: EvaluationResult[];
};

// --- Logic ---

// Helper to extract metadata from filename
// Expected format: <timestamp>_<model>_<rag_on|rag_off>/data.jsonl OR <model>_<rag>...jsonl
function extractMetadata(filePath: string) {
  const dirPath = path.dirname(filePath);
  const dirName = path.basename(dirPath);
  
  let rag = false;
  let modelName = "unknown";

  // 1. Try reading config.json in the same directory
  const configPath = path.join(dirPath, 'config.json');
  if (fs.existsSync(configPath)) {
      try {
          const config = JSON.parse(fs.readFileSync(configPath, 'utf-8'));
          if (config.rag !== undefined) rag = !!config.rag;
          if (config.model) modelName = config.model;
          
          // Map long model names to short display names
          if (modelName === AVAILABLE_MODELS.GEMINI_3_FLASH) modelName = "Gemini 3 Flash";
          else if (modelName === AVAILABLE_MODELS.GEMINI_3_PRO) modelName = "Gemini 3 Pro";
          else if (modelName === AVAILABLE_MODELS.GEMINI_2_FLASH) modelName = "Gemini 2.0 Flash";
          else if (modelName === AVAILABLE_MODELS.GPT_5_2) modelName = "GPT-5.2";
          else if (modelName === AVAILABLE_MODELS.GPT_5_MINI) modelName = "GPT-5 Mini";
          else if (modelName === AVAILABLE_MODELS.GPT_4O) modelName = "GPT-4o"; // If 4o is added later
          
          return { rag, modelName };
      } catch (e) {
          console.warn(`Failed to parse config.json at ${configPath}, falling back to filename.`);
      }
  }

  // 2. Fallback to filename heuristics
  if (dirName.includes('rag_on') || filePath.includes('rag_on')) rag = true;
  
  // Simple heuristic for model name, can be refined based on naming convention
  if (dirName.includes('gemini')) modelName = "Gemini";
  if (dirName.includes('gpt')) modelName = "GPT";
  
  // Try to find specific model identifiers
  if (dirName.includes('flash')) modelName = "Gemini Flash";
  if (dirName.includes('pro')) modelName = "Gemini Pro";
  if (dirName.includes('4o')) modelName = "GPT-4o";
  
  return { rag, modelName };
}

async function evaluateFile(filePath: string, sampleSize: number): Promise<FileEvaluationSummary> {
  const { rag, modelName } = extractMetadata(filePath);
  console.log(`\nEvaluating: ${path.basename(path.dirname(filePath))}/${path.basename(filePath)}`);
  console.log(`  -> Model: ${modelName}, RAG: ${rag ? 'ON' : 'OFF'}`);
  
  const content = fs.readFileSync(filePath, 'utf-8');
  let lines = content.split('\n').filter(line => line.trim() !== '');
  
  if (sampleSize > 0 && lines.length > sampleSize) {
      lines = lines.slice(0, sampleSize);
  }
  
  const samples = lines
    .map(line => {
        try { return JSON.parse(line); } catch { return null; }
    })
    .filter(x => x !== null);

  console.log(`  -> Sampled ${samples.length} scenarios.`);

  const model = createChatModel(EVAL_MODEL, 0); 
  const structuredJudge = model.withStructuredOutput(EvaluationSchema);
  const limit = pLimit(CONCURRENCY_LIMIT);

  const promises = samples.map((sample, index) => {
    return limit(async () => {
        const prompt = `
        ã‚ãªãŸã¯ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãªã‚·ãƒŠãƒªã‚ªãƒ‡ãƒ¼ã‚¿ã®å“è³ªã‚’è©•ä¾¡ã™ã‚‹å³æ ¼ãªå¯©æŸ»å“¡ã§ã™ã€‚
        ä»¥ä¸‹ã®ã€Œã‚·ãƒŠãƒªã‚ªè¨­å®šã€ã¨ã€ãã‚Œã«åŸºã¥ã„ã¦ç”Ÿæˆã•ã‚ŒãŸã€Œè©³ç´°ãƒ‡ãƒ¼ã‚¿ã€ã‚’èª­ã¿ã€å“è³ªã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
    
        ## ã‚·ãƒŠãƒªã‚ªè¨­å®š (Concept)
        - ãƒ†ãƒ¼ãƒ: ${sample.scenario.theme}
        - ã‚«ãƒ†ã‚´ãƒª: ${sample.scenario.category}
    
        ## ç”Ÿæˆã•ã‚ŒãŸè©³ç´°ãƒ‡ãƒ¼ã‚¿ (Cluster)
        - ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: ${sample.cluster.users.length}
        - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•°: ${sample.cluster.projects.length}
        - ã‚¢ã‚¤ãƒ†ãƒ æ•°: ${sample.cluster.items.length}
        
        ### ä»£è¡¨çš„ãªã‚¢ã‚¤ãƒ†ãƒ  (Description)
        ${sample.cluster.items.slice(0, 3).map((item: any) => `- ${item.name}: ${item.description}`).join('\n')}
    
        ### ä»£è¡¨çš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ (Bio)
        ${sample.cluster.users.slice(0, 2).map((user: any) => `- ${user.name}: ${user.bio}`).join('\n')}
    
        ## è©•ä¾¡åŸºæº– (1-5ç‚¹)
        1. **æ•´åˆæ€§ (Coherence)**: ãƒ†ãƒ¼ãƒã¨ç”Ÿæˆç‰©ã®é–“ã«çŸ›ç›¾ã¯ãªã„ã‹ï¼Ÿè¨­å®šãŒç ´ç¶»ã—ã¦ã„ãªã„ã‹ï¼Ÿ
        2. **å…·ä½“æ€§ (Specificity)**: 
           - æ‚ªã„(1-2): ã€Œç¾ã—ã„ã€ã€Œã™ã”ã„ã€ã€Œæ§˜ã€…ãªã€ãªã©ã®æŠ½è±¡çš„ãªå½¢å®¹è©ã°ã‹ã‚Šã€‚
           - è‰¯ã„(4-5): å…·ä½“çš„ãªç´ æåï¼ˆä¾‹ï¼šçœŸé®ã€ãƒ¬ã‚¸ãƒ³ï¼‰ã€æŠ€æ³•ï¼ˆä¾‹ï¼šé‡‘ç¶™ãã€3Dãƒ—ãƒªãƒ³ãƒˆï¼‰ã€å›ºæœ‰åè©ã€æ•°å€¤ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã€‚
        3. **äººé–“ã‚‰ã—ã• (Human-likeness)**: 
           - æ‚ªã„(1-2): æ•™ç§‘æ›¸çš„ã§ç„¡æ©Ÿè³ªã€‚AIç‰¹æœ‰ã®ã€Œæ•´ã„ã™ããŸã€æ–‡ç« ã€‚
           - è‰¯ã„(4-5): åŸ·ç€ã‚„åæ„›ã€ç”Ÿæ´»æ„Ÿã€ã‚ã‚‹ã„ã¯æ–‡ä½“ã«ãŠã‘ã‚‹è‡ªç„¶ãªæºã‚‰ããŒã‚ã‚‹ã€‚
        `;

        try {
            const result = await structuredJudge.invoke([
                { role: "user", content: prompt }
            ]);
            process.stdout.write('.'); // Progress dot
            return { ...result, theme: sample.scenario.theme };
        } catch (err) {
            process.stdout.write('x');
            return null;
        }
    });
  });

  const resultsRaw = await Promise.all(promises);
  const results = resultsRaw.filter(r => r !== null) as EvaluationResult[];
  
  console.log("\n  -> Completed.");

  if (results.length === 0) {
      return {
          filename: filePath, modelName, rag, sampleSize: 0,
          coherence: 0, specificity: 0, humanLikeness: 0, details: []
      };
  }

  // Calculate Averages
  const avg = (key: keyof typeof EvaluationSchema) => 
    results.reduce((sum, r) => sum + (r[key] as number), 0) / results.length;

  return {
    filename: filePath,
    modelName,
    rag,
    sampleSize: results.length,
    coherence: avg("coherence"),
    specificity: avg("specificity"),
    humanLikeness: avg("humanLikeness"),
    details: results
  };
}

// --- Main ---

async function main() {
  const args = process.argv.slice(2);
  
  let limit = DEFAULT_SAMPLE_SIZE;
  const limitIndex = args.indexOf('--limit');
  
  const files = args.filter((arg, index) => {
    if (arg.startsWith('--')) return false;
    if (index > 0 && args[index - 1] === '--limit') return false;
    return true;
  });

  if (limitIndex !== -1 && args[limitIndex + 1]) {
      limit = parseInt(args[limitIndex + 1], 10);
  }

  if (files.length === 0) {
    console.log("Usage: npx tsx llm_judge.ts <jsonl_file_1> <jsonl_file_2> ... [--limit 50]");
    process.exit(1);
  }

  const summaries: FileEvaluationSummary[] = [];

  for (const file of files) {
    const result = await evaluateFile(file, limit);
    summaries.push(result);
  }
  
  const scriptDir = __dirname;
  const reportPath = path.join(scriptDir, 'judge_results.json');

  fs.writeFileSync(reportPath, JSON.stringify(summaries, null, 2));
  console.log(`\nâœ… Evaluation complete.`);
  console.log(`ğŸ“„ Results saved to: ${reportPath}`);
  
  // Console Summary Table
  console.log("\n=== Evaluation Summary ===");
  console.log("Model | RAG | Coherence | Specificity | Human-likeness");
  console.log("------|-----|-----------|-------------|---------------");
  summaries.forEach(s => {
    console.log(`${s.modelName.padEnd(10)} | ${s.rag ? 'ON ' : 'OFF'} | ${s.coherence.toFixed(2)}      | ${s.specificity.toFixed(2)}        | ${s.humanLikeness.toFixed(2)}`);
  });
}

main();
